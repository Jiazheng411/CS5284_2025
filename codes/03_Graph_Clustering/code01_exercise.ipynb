{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture : Graph Clustering\n",
    "\n",
    "## Lab 01 : Standard k-means -- Exercise\n",
    "\n",
    "### Xavier Bresson, Jiaming Wang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/CS5284_2024_codes/codes/03_Graph_Clustering'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"path_to_file\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "#%matplotlib notebook \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "import sys; sys.path.insert(0, 'lib/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lib.utils import construct_kernel\n",
    "from lib.utils import compute_kernel_kmeans_EM\n",
    "from lib.utils import compute_kernel_kmeans_spectral\n",
    "from lib.utils import compute_purity\n",
    "from lib.utils import construct_knn_graph\n",
    "from lib.utils import compute_ncut\n",
    "from lib.utils import compute_pcut\n",
    "from lib.utils import graph_laplacian\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model (GMM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load raw data images\n",
    "mat = scipy.io.loadmat('datasets/GMM.mat')\n",
    "X = mat['X']\n",
    "n = X.shape[0]\n",
    "d = X.shape[1]\n",
    "Cgt = mat['Cgt'] - 1; Cgt = Cgt.squeeze()\n",
    "nc = len(np.unique(Cgt))\n",
    "print(n,d,nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "size_vertex_plot = 10\n",
    "plt.scatter(X[:,0], X[:,1], s=size_vertex_plot*np.ones(n), c=Cgt, cmap='jet')\n",
    "plt.title('Gaussian Mixture Model (GMM) -- Linearly separable data points')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Evaluating the impact of different initializations on k-Means performance\n",
    "\n",
    "**Initialization Methods:**\n",
    "* **Constant Function:** You can use `numpy.ones()` for this initialization.\n",
    "* **Random Function:** Consider `numpy.random.randint()` for random initialization.\n",
    "\n",
    "Discuss how these initialization methods affect the clustering results on the distribution of a Gaussian Mixture Model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "n = X.shape[0]\n",
    "C_kmeans = # YOUR CODE HERE \n",
    "\n",
    "# Linear Kernel for standard K-Means\n",
    "Ker = X.dot(X.T)\n",
    "print(Ker.shape)\n",
    "\n",
    "# Loop\n",
    "Cold = np.ones([n])\n",
    "diffC = 1e10\n",
    "Theta = np.ones(n) # Same weight for each data\n",
    "Theta = np.diag(Theta)\n",
    "Ones = np.ones((1,n))\n",
    "En_iters = []\n",
    "Clusters_iters = []; Clusters_iters.append(C_kmeans)\n",
    "k = 0\n",
    "while (k<50) & (diffC>1e-2):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "    #print(k)\n",
    "    \n",
    "    # Distance Matrix D\n",
    "    row = np.array(range(n))\n",
    "    col = C_kmeans\n",
    "    data = np.ones(n)\n",
    "    F = scipy.sparse.csr_matrix((data, (row, col)), shape=(n, nc)).todense()\n",
    "    O = np.diag( np.array( 1./ (Ones.dot(Theta).dot(F) + 1e-6) ).squeeze() )\n",
    "    T = Ker.dot(Theta.dot(F.dot(O)))\n",
    "    D = - 2* T + np.repeat( np.diag(O.dot((F.T).dot(Theta.dot(T))))[None,:] ,n,axis=0)\n",
    "    #print(D.shape)\n",
    "    \n",
    "    # Extract clusters\n",
    "    C_kmeans = np.array(np.argmin(D,1)).squeeze()\n",
    "    Clusters_iters.append(C_kmeans)\n",
    "                \n",
    "    # L2 difference between two successive cluster configurations\n",
    "    diffC = np.linalg.norm(C_kmeans-Cold)/np.linalg.norm(Cold)\n",
    "    Cold = C_kmeans\n",
    "        \n",
    "    # K-Means energy\n",
    "    En = np.multiply( (np.repeat(np.diag(Ker)[:,None],nc,axis=1) + D) , F)\n",
    "    En_kmeans = np.sum(En)/n\n",
    "    En_iters.append(En_kmeans)\n",
    "    \n",
    "print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize k-means iterations\n",
    "fig, ax = plt.subplots()\n",
    "for k,C in enumerate(Clusters_iters):\n",
    "    plt.scatter(X[:,0], X[:,1], s=10*np.ones(n), c=C, cmap='jet')\n",
    "    plt.title('k-means clusters at iteration = ' + str(k+1) )\n",
    "    display(fig)\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize loss vs iteration\n",
    "plt.figure(3)\n",
    "plt.plot(En_iters)\n",
    "plt.title('loss vs iteration')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two concentric circles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load raw data images\n",
    "mat = scipy.io.loadmat('datasets/two_circles.mat')\n",
    "X = mat['X']\n",
    "n = X.shape[0]\n",
    "d = X.shape[1]\n",
    "Cgt = mat['Cgt'] - 1; Cgt = Cgt.squeeze()\n",
    "nc = len(np.unique(Cgt))\n",
    "print(n,d,nc)\n",
    "\n",
    "plt.figure(10)\n",
    "size_vertex_plot = 10\n",
    "plt.scatter(X[:,0], X[:,1], s=size_vertex_plot*np.ones(n), c=Cgt, cmap='jet')\n",
    "plt.title('Distribution of two circle distributions -- Non-linear data points')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Assessing k-Means performance with various initializations\n",
    "\n",
    "Can you identify an initialization function that successfully separates the two classes in this dataset? \n",
    "\n",
    "Evaluate the effectiveness of k-means on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "n = X.shape[0]\n",
    "C_kmeans = # YOUR CODE HERE \n",
    "\n",
    "# Linear Kernel for standard K-Means\n",
    "Ker = X.dot(X.T)\n",
    "print(Ker.shape)\n",
    "\n",
    "# Loop\n",
    "Cold = np.ones([n])\n",
    "diffC = 1e10\n",
    "Theta = np.ones(n) # Equal weight for each data\n",
    "Theta = np.diag(Theta)\n",
    "Ones = np.ones((1,n))\n",
    "En_iters = []\n",
    "Clusters_iters = []; Clusters_iters.append(C_kmeans)\n",
    "k = 0\n",
    "while (k<10) & (diffC>1e-2):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "    #print(k)\n",
    "    \n",
    "    # Distance Matrix D\n",
    "    row = np.array(range(n))\n",
    "    col = C_kmeans\n",
    "    data = np.ones(n)\n",
    "    F = scipy.sparse.csr_matrix((data, (row, col)), shape=(n, nc)).todense()\n",
    "    O = np.diag( np.array( 1./ (Ones.dot(Theta).dot(F) + 1e-6) ).squeeze() )\n",
    "    T = Ker.dot(Theta.dot(F.dot(O)))\n",
    "    D = - 2* T + np.repeat( np.diag(O.dot((F.T).dot(Theta.dot(T))))[None,:] ,n,axis=0)\n",
    "    #print(D.shape)\n",
    "    \n",
    "    # Extract clusters\n",
    "    C_kmeans = np.array(np.argmin(D,1)).squeeze()\n",
    "    Clusters_iters.append(C_kmeans)\n",
    "                \n",
    "    # L2 difference between two successive cluster configurations\n",
    "    diffC = np.linalg.norm(C_kmeans-Cold)/np.linalg.norm(Cold)\n",
    "    Cold = C_kmeans\n",
    "        \n",
    "    # K-Means energy\n",
    "    En = np.multiply( (np.repeat(np.diag(Ker)[:,None],nc,axis=1) + D) , F)\n",
    "    En_kmeans = np.sum(En)/n\n",
    "    En_iters.append(En_kmeans)\n",
    "    \n",
    "print(k)\n",
    "\n",
    "# Visualize k-means iterations\n",
    "fig, ax = plt.subplots()\n",
    "for k,C in enumerate(Clusters_iters):\n",
    "    plt.scatter(X[:,0], X[:,1], s=10*np.ones(n), c=C, cmap='jet')\n",
    "    plt.title('k-means clusters at iteration = ' + str(k+1) )\n",
    "    display(fig)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "# Visualize loss vs iteration\n",
    "plt.figure(12)\n",
    "plt.plot(En_iters)\n",
    "plt.title('loss vs iteration')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
