{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture : Recommendation on Graphs\n",
    "\n",
    "## Lab 04 : Hybrid recommendation -- Exercise\n",
    "\n",
    "### Xavier Bresson, Nian Liu  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/CS5284_2024_codes/codes/05_Recommendation'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"path_to_file\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook \n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "import sys; sys.path.insert(0, 'lib/')\n",
    "from lib.utils import shrink\n",
    "from lib.utils import graph_laplacian\n",
    "import scipy.sparse.linalg\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graphs of rows/users and columns/movies\n",
    "mat = scipy.io.loadmat('datasets/synthetic_netflix.mat')\n",
    "M = mat['M']\n",
    "Otraining = mat['Otraining']\n",
    "Otest = mat['Otest']\n",
    "Wrow = mat['Wrow']\n",
    "Wcol = mat['Wcol']\n",
    "n,m = M.shape\n",
    "print('n,m=',n,m)\n",
    "\n",
    "Mgt = M # Ground truth\n",
    "O = Otraining\n",
    "M = O* Mgt\n",
    "perc_obs_training = np.sum(Otraining) / (n*m)\n",
    "print('perc_obs_training=',perc_obs_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viusalize the rating matrix\n",
    "plt.figure(1)\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Low-rank Matrix M.\\nNote: We NEVER observe it\\n in real-world applications')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Observed values of M\\n for TRAINING.\\n Percentage=' + str(perc_obs_training))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 : Implement hybrid recommendation by combining collaborative and content filtering\n",
    "\n",
    "Design an optimization algorithm that integrates the previous approaches.\n",
    "\n",
    "- Update the dual variable Y using SVD and the shrinkage operator, similar to the approach in `code02`.\n",
    "- Update the dual variable X by solving the linear system Ax = b using conjugate gradient, as demonstrated in `code03`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid system : Matrix Completion on graphs\n",
    "\n",
    "# Norm of the operator\n",
    "OM = O*M\n",
    "normOM = np.linalg.norm(OM,2)\n",
    "\n",
    "#######################################\n",
    "# Select the set of hyper-parameters\n",
    "#######################################\n",
    "\n",
    "# scenario : very low number of ratings, 0.03%, error metric = 112.68\n",
    "lambdaDir = 1e-1 * 1e0; lambdaDF = 1e3; lambdaNuc = normOM/4; alpha = 0.1\n",
    "\n",
    "#Compute Graph Laplacians\n",
    "Lr = graph_laplacian(Wrow)\n",
    "Lc = graph_laplacian(Wcol)\n",
    "I = scipy.sparse.identity(m, dtype=Lr.dtype)\n",
    "Lr = scipy.sparse.kron( I, Lr )\n",
    "Lr = scipy.sparse.csr_matrix(Lr)\n",
    "I = scipy.sparse.identity(n, dtype=Lc.dtype)\n",
    "Lc = scipy.sparse.kron( Lc, I )\n",
    "Lc = scipy.sparse.csr_matrix(Lc)\n",
    "\n",
    "# Indentify zero columns and zero rows in the data matrix X\n",
    "idx_zero_cols = np.where(np.sum(Otraining,axis=0)<1e-9)[0]\n",
    "idx_zero_rows = np.where(np.sum(Otraining,axis=1)<1e-9)[0]\n",
    "nb_zero_cols = len(idx_zero_cols)\n",
    "nb_zero_rows = len(idx_zero_rows) \n",
    " \n",
    "# Pre-processing\n",
    "L = alpha* Lc + (1.-alpha)* Lr \n",
    "vecO = np.reshape(O.T,[-1]) \n",
    "vecO = scipy.sparse.diags(vecO, 0, shape=(n*m, n*m) ,dtype=L.dtype)\n",
    "vecO = scipy.sparse.csr_matrix(vecO) \n",
    "At = lambdaDir* L + lambdaDF* vecO \n",
    "vecM = np.reshape(M.T,[-1])\n",
    "bt = lambdaDF* scipy.sparse.csr_matrix( vecM ).T\n",
    "bt = np.array(bt.todense()).squeeze()\n",
    "Id = scipy.sparse.identity(n*m)\n",
    "Id = scipy.sparse.csr_matrix(Id) \n",
    "\n",
    "# Initialization\n",
    "X = M; Xb = X;\n",
    "Y = np.zeros([n,m])\n",
    "normA = 1.\n",
    "sigma = 1./normA\n",
    "tau = 1./normA\n",
    "diffX = 1e10\n",
    "min_nm = np.min([n,m])\n",
    "k = 0\n",
    "while (k<2000) & (diffX>1e-1):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "\n",
    "    ############################################################################\n",
    "    # Your code starts\n",
    "    # Update dual variable Y\n",
    "    ############################################################################\n",
    "    Y = \n",
    "    ############################################################################\n",
    "    # Your code ends\n",
    "    ############################################################################\n",
    "\n",
    "    ############################################################################\n",
    "    # Your code starts\n",
    "    # Update primal variable X\n",
    "    ############################################################################\n",
    "    Xold = X\n",
    "    X = \n",
    "    # Fix values with no observations along some rows and columns\n",
    "    r,c = np.where(X>0.0); median = np.median(X[r,c])\n",
    "    if nb_zero_cols>0: X[:,idx_zero_cols] = median\n",
    "    if nb_zero_rows>0: X[nb_zero_rows,:] = median\n",
    "    ############################################################################\n",
    "    # Your code ends\n",
    "    ############################################################################\n",
    "\n",
    "    # Update primal variable xb\n",
    "    Xb = 2.* X - Xold\n",
    "    \n",
    "    # Difference between two iterations\n",
    "    diffX = np.linalg.norm(X-Xold)\n",
    "    \n",
    "    # Reconstruction error\n",
    "    err_test = np.sqrt(np.sum((Otest*(X-Mgt))**2)) / np.sum(Otest) * (n*m)\n",
    "    \n",
    "    # Plot\n",
    "    if not k%10:\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(1)\n",
    "        plt.imshow(X, interpolation='nearest', cmap='jet')\n",
    "        plt.title('Hybrid Filtering\\nIteration='+ str(k)+'\\nReconstruction Error= '+ str(round(err_test,5)))\n",
    "        plt.show()        \n",
    "        print('diffX',diffX)\n",
    "\n",
    "\n",
    "clear_output(wait=True) \n",
    "print('Reconstruction Error: '+ str(round(err_test,5)))\n",
    "\n",
    "# Final plot\n",
    "plt.figure(2)\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Ground truth low-rank matrix M')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Observed values of M')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.imshow(X, interpolation='nearest', cmap='jet')\n",
    "plt.title('Hybrid Filtering\\nIteration='+ str(k)+'\\nReconstruction Error= '+ str(round(err_test,2)))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-world dataset SWEETRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore different sparsity scenarios for real-world ratings\n",
    "\n",
    "Consider the following sparsity scenarios:\n",
    "* Scenario 1: 1.3% known ratings\n",
    "* Scenario 2: 13.1% known ratings\n",
    "* Scenario 3: 52.7% known ratings\n",
    "\n",
    "Reproduce the results shown in Slide 49 for the hybrid recommendation system:\n",
    "1. When the number of ratings is small, the hybrid method performs similarly to the graph diffusion method.\n",
    "2. When the number of ratings is large, the hybrid method privides similar results to the low-rank method.\n",
    "3. For an intermediate number of ratings, the hybrid method outperforms both the low-rank and graph diffusion methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graphs of rows/users and columns/products\n",
    "mat = scipy.io.loadmat('datasets/real_sweetrs_scenario1.mat')\n",
    "mat = scipy.io.loadmat('datasets/real_sweetrs_scenario2.mat')\n",
    "# mat = scipy.io.loadmat('datasets/real_sweetrs_scenario3.mat')\n",
    "M = mat['M']\n",
    "Otraining = mat['Otraining']\n",
    "Otest = mat['Otest']\n",
    "Wrow = mat['Wrow']\n",
    "Wcol = mat['Wcol']\n",
    "print('M', M.shape)\n",
    "print('Otraining', Otraining.shape)\n",
    "print('Otest', Otest.shape)\n",
    "print('Wrow', Wrow.shape)\n",
    "print('Wcol', Wcol.shape)\n",
    "\n",
    "n,m = M.shape\n",
    "print('n,m=',n,m)\n",
    "\n",
    "Mgt = M # Ground truth\n",
    "O = Otraining\n",
    "M = O* Mgt\n",
    "perc_obs_training = np.sum(Otraining)/(n*m)\n",
    "print('perc_obs_training=',perc_obs_training)\n",
    "perc_obs_test = np.sum(Otest) / (n*m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original rating matrix\n",
    "plt.figure(1,figsize=(10,10))\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Original rating matrix\\n Percentage observed ratings: ' + str(100*np.sum(Mgt>0)/(n*m))[:5])\n",
    "\n",
    "# Visualize the observed rating matrix\n",
    "plt.figure(2, figsize=(10,10))\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Observed rating matrix\\n Percentage observed ratings: ' + str(100*perc_obs_training)[:5])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid system : Matrix Completion on graphs\n",
    "\n",
    "# Norm of the operator\n",
    "OM = O*M\n",
    "normOM = np.linalg.norm(OM,2)\n",
    "\n",
    "#######################################\n",
    "# Select the set of hyper-parameters\n",
    "#######################################\n",
    "\n",
    "# scenario 1 : low number of ratings, e.g. 1.3%, error metric = 402.71\n",
    "lambdaDir = 1e-1 * 1e3 * 0.5; lambdaDF = 1e3; lambdaNuc = normOM/4; alpha = 0.02 \n",
    "\n",
    "# # scenario 2 : intermediate number of ratings, e.g. 13.1%, error metric = 397.47\n",
    "lambdaDir = 1e-1; lambdaDF = 1e3 * 10; lambdaNuc = normOM/4 /10; alpha = 0.25 \n",
    "\n",
    "# # # scenario 3 : large number of ratings, e.g. 52.7%, error metric = 695.00\n",
    "# lambdaDir = 1e-1 * 1e1; lambdaDF = 1e3; lambdaNuc = normOM/4; alpha = 0.02\n",
    "\n",
    "\n",
    "#Compute Graph Laplacians\n",
    "Lr = graph_laplacian(Wrow)\n",
    "Lc = graph_laplacian(Wcol)\n",
    "I = scipy.sparse.identity(m, dtype=Lr.dtype)\n",
    "Lr = scipy.sparse.kron( I, Lr )\n",
    "Lr = scipy.sparse.csr_matrix(Lr)\n",
    "I = scipy.sparse.identity(n, dtype=Lc.dtype)\n",
    "Lc = scipy.sparse.kron( Lc, I )\n",
    "Lc = scipy.sparse.csr_matrix(Lc)\n",
    "\n",
    "# Indentify zero columns and zero rows in the data matrix X\n",
    "idx_zero_cols = np.where(np.sum(Otraining,axis=0)<1e-9)[0]\n",
    "idx_zero_rows = np.where(np.sum(Otraining,axis=1)<1e-9)[0]\n",
    "nb_zero_cols = len(idx_zero_cols)\n",
    "nb_zero_rows = len(idx_zero_rows)\n",
    "\n",
    "# Pre-processing\n",
    "L = alpha* Lc + (1.-alpha)* Lr \n",
    "vecO = np.reshape(O.T,[-1]) \n",
    "vecO = scipy.sparse.diags(vecO, 0, shape=(n*m, n*m) ,dtype=L.dtype)\n",
    "vecO = scipy.sparse.csr_matrix(vecO) \n",
    "At = lambdaDir* L + lambdaDF* vecO \n",
    "vecM = np.reshape(M.T,[-1])\n",
    "bt = lambdaDF* scipy.sparse.csr_matrix( vecM ).T\n",
    "bt = np.array(bt.todense()).squeeze()\n",
    "Id = scipy.sparse.identity(n*m)\n",
    "Id = scipy.sparse.csr_matrix(Id) \n",
    "\n",
    "# Initialization\n",
    "X = M; Xb = X;\n",
    "Y = np.zeros([n,m])\n",
    "normA = 1.\n",
    "sigma = 1./normA\n",
    "tau = 1./normA\n",
    "diffX = 1e10\n",
    "min_nm = np.min([n,m])\n",
    "k = 0\n",
    "while (k<2000) & (diffX>1e-1):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "        \n",
    "    # Update dual variable y\n",
    "    Y = Y + sigma* Xb\n",
    "    U,S,V = np.linalg.svd(Y/sigma) # % Y/sigma = U*S*V'\n",
    "    Sdiag = shrink( S , lambdaNuc/ sigma )\n",
    "    I = np.array(range(min_nm))\n",
    "    Sshrink = np.zeros([n,m])\n",
    "    Sshrink[I,I] = Sdiag\n",
    "    Y = Y - sigma* U.dot(Sshrink.dot(V))    \n",
    "    \n",
    "    # Update primal variable x\n",
    "    Xold = X\n",
    "    X = X - tau* Y\n",
    "    A = tau* At + Id\n",
    "    vecX = np.reshape(X.T,[-1]) \n",
    "    vecX = scipy.sparse.csr_matrix(vecX) \n",
    "    b = tau* bt + vecX\n",
    "    b = np.array(b).squeeze()    \n",
    "    \n",
    "    # Solve by linear system\n",
    "    x,_ = scipy.sparse.linalg.cg(A, b, x0=b, tol=1e-6, maxiter=25)\n",
    "    X = np.reshape(x,[m,n]).T\n",
    "    # Fix issue with no observations along some rows and columns\n",
    "    r,c = np.where(X>0.0); median = np.median(X[r,c])\n",
    "    if nb_zero_cols>0: X[:,idx_zero_cols] = median\n",
    "    if nb_zero_rows>0: X[nb_zero_rows,:] = median\n",
    "        \n",
    "    # Update primal variable xb\n",
    "    Xb = 2.* X - Xold\n",
    "        \n",
    "    # Difference between two iterations\n",
    "    diffX = np.linalg.norm(X-Xold)\n",
    "        \n",
    "    # Reconstruction error\n",
    "    err_test = np.sqrt(np.sum((Otest*(X-Mgt))**2)) / np.sum(Otest) * (n*m)\n",
    "    \n",
    "    # Plot\n",
    "    if not k%10:\n",
    "        clear_output(wait=True)   \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(X, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "        plt.colorbar(shrink=0.65)\n",
    "        plt.title('Hybrib Filtering\\nIteration='+ str(k)+'\\nReconstruction Error= '+ str(round(err_test,5)))\n",
    "        plt.show()\n",
    "        print('diffX',diffX)\n",
    "\n",
    "clear_output(wait=True) \n",
    "print('Reconstruction Error: '+ str(round(err_test,5)))\n",
    "\n",
    "# Final plots\n",
    "plt.figure(2, figsize=(10,10))\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Original rating matrix\\n Percentage observed ratings: ' + str(100*np.sum(Mgt>0)/(n*m))[:5])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3, figsize=(10,10))\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Observed rating matrix\\n Percentage observed ratings: ' + str(100*perc_obs_training)[:5])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4, figsize=(10,10))\n",
    "plt.imshow(X, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Hybrib Filtering\\nIteration='+ str(k)+'\\nReconstruction Error= '+ str(round(err_test,5)))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
