{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture : Recommendation on Graphs\n",
    "\n",
    "## Lab 03 : Content recommendation -- Exercise\n",
    "\n",
    "### Xavier Bresson, Nian Liu  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/CS5284_2024_codes/codes/05_Recommendation'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"path_to_file\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook \n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import time\n",
    "import sys; sys.path.insert(0, 'lib/')\n",
    "from lib.utils import shrink\n",
    "from lib.utils import graph_laplacian\n",
    "import scipy.sparse.linalg\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from lib.utils import compute_ncut, reindex_W_with_classes, construct_knn_graph\n",
    "import torch\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graphs of rows/users and columns/movies\n",
    "mat = scipy.io.loadmat('datasets/synthetic_netflix.mat')\n",
    "M = mat['M']\n",
    "Otraining = mat['Otraining']\n",
    "Otest = mat['Otest']\n",
    "Wrow = mat['Wrow']\n",
    "Wcol = mat['Wcol']\n",
    "n,m = M.shape\n",
    "print('n,m=',n,m)\n",
    "\n",
    "Mgt = M # Ground truth\n",
    "O = Otraining\n",
    "M = O* Mgt\n",
    "perc_obs_training = np.sum(Otraining) / (n*m)\n",
    "print('perc_obs_training=',perc_obs_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viusalize the rating matrix\n",
    "plt.figure(1)\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Low-rank Matrix M.\\nNote: We NEVER observe it\\n in real-world applications')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Observed values of M\\n for TRAINING.\\n Percentage=' + str(perc_obs_training))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Implement content filtering using graph regularization with Dirichlet energy loss\n",
    "\n",
    "Refer to Slide 44 of Lecture 5.\n",
    "\n",
    "**Key Steps:**\n",
    "1. **Graph Laplacians:** Calculate the graph Laplacians for both the rows and columns. Use the `graph_laplacian()` function.\n",
    "2. **Matrix Construction:** Construct matrix A and vector b for the linear system Ax = b, as shown on Slide 44. You may find the following functions helpful: `scipy.sparse.kron()` for the Kronecker product of two matrices, `scipy.sparse.identity()`, `scipy.sparse.csr_matrix()`, `scipy.sparse.diags()`, and `numpy.reshape()`.\n",
    "3. **Solve the Linear System:** Solve the linear system x = A$^{-1}$b. You can use the conjugate gradient method with `scipy.sparse.linalg.cg()`.\n",
    "\n",
    "Note: Pay close attention to matrix dimensions at each stage of the algorithm to ensure correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content Filtering / Graph Regularization by Dirichlet Energy\n",
    "\n",
    "#######################################\n",
    "# Select the set of hyper-parameters\n",
    "#######################################\n",
    "\n",
    "# scenario : very low number of ratings, 0.03%, error metric = 161.32\n",
    "lambdaDir = 1e-1; lambdaDF = 1e3; alpha = 0.02\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# Your code starts\n",
    "# Compute graph Laplacians\n",
    "############################################################################\n",
    "Lr = graph_laplacian()\n",
    "Lc = graph_laplacian()\n",
    "############################################################################\n",
    "# Your code ends\n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "# Your code starts\n",
    "# Complete Kronecker products\n",
    "############################################################################\n",
    "Lr = \n",
    "Lc = \n",
    "L = alpha* Lc + (1.-alpha)* Lr\n",
    "############################################################################\n",
    "# Your code ends\n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "# Your code starts\n",
    "# Calculate A and b\n",
    "############################################################################\n",
    "vecO = np.reshape(O.T,[-1])\n",
    "matO = \n",
    "A = lambdaDir* L + lambdaDF* matO\n",
    "vecM = np.reshape(M.T,[-1])\n",
    "b = \n",
    "############################################################################\n",
    "# Your code ends\n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "# Your code starts\n",
    "# Solve Ax=b by conjugate gradient\n",
    "############################################################################\n",
    "x = \n",
    "X = np.reshape(x,[m,n]).T\n",
    "############################################################################\n",
    "# Your code ends\n",
    "############################################################################\n",
    "\n",
    "\n",
    "# Reconstruction error\n",
    "err_test = np.sqrt(np.sum((Otest*(X-Mgt))**2)) / np.sum(Otest) * (n*m)\n",
    "print('Reconstruction Error: '+ str(round(err_test,5)))\n",
    "\n",
    "# Plot\n",
    "plt.figure(2)\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Ground truth low-rank matrix M')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Observed values of M')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.imshow(X, interpolation='nearest', cmap='jet')\n",
    "plt.title('Content Filtering\\nReconstruction Error= '+ str(round(err_test,5)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-world dataset SWEETRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : Explore different sparsity scenarios for real-world ratings\n",
    "\n",
    "Try out the following sparsity scenarios:\n",
    "* Scenario 1 : 1.3% known ratings\n",
    "* Scenario 2 : 13.1% known ratings\n",
    "* Scenario 3 : 52.7% known ratings\n",
    "\n",
    "With the reconstruction term weight set to `lambdaDF = 1e1`, should the weight of the graph Dirichlet term `lambdaDir` be adjusted (increased or decreased) as the percentage of available ratings decreases?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graphs of rows/users and columns/products\n",
    "mat = scipy.io.loadmat('datasets/real_sweetrs_scenario1.mat') # 1.3%\n",
    "mat = scipy.io.loadmat('datasets/real_sweetrs_scenario2.mat') # 13.1%\n",
    "# mat = scipy.io.loadmat('datasets/real_sweetrs_scenario3.mat') # 52.7%\n",
    "M = mat['M']\n",
    "Otraining = mat['Otraining']\n",
    "Otest = mat['Otest']\n",
    "Wrow = mat['Wrow']\n",
    "Wcol = mat['Wcol']\n",
    "print('M', M.shape)\n",
    "print('Otraining', Otraining.shape)\n",
    "print('Otest', Otest.shape)\n",
    "print('Wrow', Wrow.shape)\n",
    "print('Wcol', Wcol.shape)\n",
    "\n",
    "n,m = M.shape\n",
    "print('n,m=',n,m)\n",
    "\n",
    "Mgt = M # Ground truth\n",
    "O = Otraining\n",
    "M = O* Mgt\n",
    "perc_obs_training = np.sum(Otraining)/(n*m)\n",
    "print('perc_obs_training=',perc_obs_training)\n",
    "perc_obs_test = np.sum(Otest) / (n*m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original rating matrix\n",
    "plt.figure(1,figsize=(10,10))\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Original rating matrix\\n Percentage observed ratings: ' + str(100*np.sum(Mgt>0)/(n*m))[:5])\n",
    "\n",
    "# Visualize the observed rating matrix\n",
    "plt.figure(2, figsize=(10,10))\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Observed rating matrix\\n Percentage observed ratings: ' + str(100*perc_obs_training)[:5])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize graph of users and graph of products\n",
    " # Plot adjacency matrix w.r.t. NCut communities\n",
    "\n",
    "# plot graph of users\n",
    "W = Wrow\n",
    "nc = 10; Cncut, _ = compute_ncut(W, np.zeros(Mgt.shape[0]), nc)# compute NCut clustering \n",
    "[reindexed_W_ncut,reindexed_C_ncut] = reindex_W_with_classes(W,Cncut)\n",
    "plt.figure(1)\n",
    "plt.spy(reindexed_W_ncut, precision=0.01, markersize=1)\n",
    "plt.title('Adjacency matrix of users indexed \\naccording to the NCut communities')\n",
    "plt.show()\n",
    "A = W.copy()\n",
    "A.setdiag(0) \n",
    "A.eliminate_zeros()\n",
    "G_nx = nx.from_scipy_sparse_array(A)\n",
    "plt.figure(2,figsize=[30,30])\n",
    "nx.draw_networkx(G_nx, with_labels=True, node_color=np.array(Cncut), cmap='jet')\n",
    "\n",
    "# plot graph of products\n",
    "W = Wcol\n",
    "nc = 10; Cncut, _ = compute_ncut(W, np.zeros(Mgt.shape[1]), nc)# compute NCut clustering \n",
    "[reindexed_W_ncut,reindexed_C_ncut] = reindex_W_with_classes(W,Cncut)\n",
    "plt.figure(3)\n",
    "plt.spy(reindexed_W_ncut, precision=0.01, markersize=1)\n",
    "plt.title('Adjacency matrix of products indexed \\naccording to the NCut communities')\n",
    "plt.show()\n",
    "A = W.copy()\n",
    "A.setdiag(0) \n",
    "A.eliminate_zeros()\n",
    "G_nx = nx.from_scipy_sparse_array(A)\n",
    "plt.figure(4,figsize=[30,30])\n",
    "nx.draw_networkx(G_nx, with_labels=True, node_color=np.array(Cncut), cmap='jet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content Filtering / Graph Regularization by Dirichlet Energy\n",
    "\n",
    "#######################################\n",
    "# Select the set of hyper-parameters\n",
    "#######################################\n",
    "\n",
    "# scenario 1 : low number of ratings, e.g. 1.3%, error metric = 399.81\n",
    "lambdaDir = 1e-1 * XXX; lambdaDF = 1e1; alpha = 0.02\n",
    "\n",
    "# scenario 2 : intermediate number of ratings, e.g. 13.1%, error metric = 411.25\n",
    "lambdaDir = 1e-1 * XXX; lambdaDF = 1e1; alpha = 0.02\n",
    "\n",
    "# scenario 3 : large number of ratings, e.g. 52.7%, error metric = 748.52\n",
    "# lambdaDir = 1e-1 * XXX; lambdaDF = 1e1; alpha = 0.02\n",
    "\n",
    "\n",
    "# Compute Graph Laplacians\n",
    "Lr = graph_laplacian(Wrow)\n",
    "Lc = graph_laplacian(Wcol)\n",
    "I = scipy.sparse.identity(m, dtype=Lr.dtype)\n",
    "Lr = scipy.sparse.kron( I, Lr )\n",
    "Lr = scipy.sparse.csr_matrix(Lr)\n",
    "I = scipy.sparse.identity(n, dtype=Lc.dtype)\n",
    "Lc = scipy.sparse.kron( Lc, I )\n",
    "Lc = scipy.sparse.csr_matrix(Lc)\n",
    "\n",
    "# Pre-processing\n",
    "L = alpha* Lc + (1.-alpha)* Lr \n",
    "vecO = np.reshape(O.T,[-1]) \n",
    "vecO = scipy.sparse.diags(vecO, 0, shape=(n*m, n*m) ,dtype=L.dtype)\n",
    "vecO = scipy.sparse.csr_matrix(vecO) \n",
    "At = lambdaDir* L + lambdaDF* vecO \n",
    "vecM = np.reshape(M.T,[-1])\n",
    "bt = lambdaDF* scipy.sparse.csr_matrix( vecM ).T\n",
    "bt = np.array(bt.todense()).squeeze()\n",
    "\n",
    "# Solve by linear system\n",
    "x,_ = scipy.sparse.linalg.cg(At, bt, x0=bt, tol=1e-9, maxiter=100)\n",
    "X = np.reshape(x,[m,n]).T\n",
    " \n",
    "# Reconstruction error\n",
    "err_test = np.sqrt(np.sum((Otest*(X-Mgt))**2)) / np.sum(Otest) * (n*m)\n",
    "print('Reconstruction Error: '+ str(round(err_test,5)))\n",
    "\n",
    "# Plots\n",
    "plt.figure(2, figsize=(10,10))\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Original rating matrix\\n Percentage observed ratings: ' + str(100*np.sum(Mgt>0)/(n*m))[:5])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3, figsize=(10,10))\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Observed rating matrix\\n Percentage observed ratings: ' + str(100*perc_obs_training)[:5])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4, figsize=(10,10))\n",
    "plt.imshow(X, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Content Filtering\\nReconstruction Error= '+ str(round(err_test,5)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
