{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture : Recommendation on Graphs\n",
    "\n",
    "## Lab 02 : Collaborative recommendation -- Exercise\n",
    "\n",
    "### Xavier Bresson, Nian Liu  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/CS5284_2024_codes/codes/05_Recommendation'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"path_to_file\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook \n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import time\n",
    "import sys; sys.path.insert(0, 'lib/')\n",
    "from lib.utils import shrink\n",
    "import scipy.sparse.linalg\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graphs of rows/users and columns/movies\n",
    "mat = scipy.io.loadmat('datasets/synthetic_netflix.mat')\n",
    "M = mat['M']\n",
    "Otraining = mat['Otraining']\n",
    "Otest = mat['Otest']\n",
    "Wrow = mat['Wrow']\n",
    "Wcol = mat['Wcol']\n",
    "n,m = M.shape\n",
    "print('n,m=',n,m)\n",
    "\n",
    "Mgt = M # Ground truth\n",
    "O = Otraining\n",
    "M = O* Mgt\n",
    "perc_obs_training = np.sum(Otraining) / (n*m)\n",
    "print('perc_obs_training=',perc_obs_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viusalize the rating matrix\n",
    "plt.figure(1)\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Low-rank Matrix M.\\nNote: We NEVER observe it\\n in real-world applications')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Observed values of M\\n for TRAINING.\\n Percentage=' + str(perc_obs_training))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Implement collaborative filtering using low-rank optimization with nuclear norm\n",
    "\n",
    "Refer to Slide 30 of Lecture 5.\n",
    "\n",
    "**Main Steps:**\n",
    "1. Compute the SVD of the matrix $Y^k + \\sigma^k X^k = U \\Sigma V^\\top$.\n",
    "2. Update the dual variable $Y^{k+1}$.\n",
    "3. Update the primal variable $X^{k+1}$.\n",
    "4. For rows or columns without observations, fill in with the median value of the computed matrix $X$.\n",
    "\n",
    "Hint: You may use the function `numpy.linalg.svd()` for SVD computation and the `shrink()` function for nuclear norm minimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering / low-rank approximation by nuclear norm\n",
    "\n",
    "# Norm of the operator\n",
    "OM = O*M\n",
    "normOM = np.linalg.norm(OM,2)\n",
    "\n",
    "#######################################\n",
    "# Select the set of hyper-parameters\n",
    "#######################################\n",
    "\n",
    "# scenario : very low number of ratings, 0.03%, error metric = 138.75\n",
    "lambdaNuc = normOM/4; lambdaDF = 1e1\n",
    "\n",
    "# Indentify zero columns and zero rows in the data matrix X\n",
    "idx_zero_cols = np.where(np.sum(Otraining,axis=0)<1e-9)[0]\n",
    "idx_zero_rows = np.where(np.sum(Otraining,axis=1)<1e-9)[0]\n",
    "nb_zero_cols = len(idx_zero_cols)\n",
    "nb_zero_rows = len(idx_zero_rows)\n",
    "   \n",
    "# Initialization\n",
    "X = M; Xb = X;\n",
    "Y = np.zeros([n,m])\n",
    "normA = 1.\n",
    "sigma = 1./normA\n",
    "tau = 1./normA\n",
    "diffX = 1e10\n",
    "min_nm = np.min([n,m])\n",
    "k = 0\n",
    "while (k<2000) & (diffX>1e-1):\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "        \n",
    "    ############################################################################\n",
    "    # Your code start\n",
    "    # Update the dual variable Y\n",
    "    ############################################################################\n",
    "    Y = \n",
    "    ############################################################################\n",
    "    # Your code end\n",
    "    ############################################################################\n",
    "    \n",
    "    ############################################################################\n",
    "    # Your code start\n",
    "    # Update the primal variable X\n",
    "    ############################################################################\n",
    "    Xold = X\n",
    "    X = \n",
    "    ############################################################################\n",
    "    # Your code end\n",
    "    ############################################################################\n",
    "    \n",
    "    # Fix issue with no observations along some rows and columns\n",
    "    r,c = np.where(X>0.0); median = np.median(X[r,c])\n",
    "    if nb_zero_cols>0: X[:,idx_zero_cols] = median\n",
    "    if nb_zero_rows>0: X[nb_zero_rows,:] = median\n",
    "\n",
    "    # Update primal variable xb\n",
    "    Xb = 2.* X - Xold\n",
    "        \n",
    "    # Difference between two iterations\n",
    "    diffX = np.linalg.norm(X-Xold) \n",
    "    \n",
    "    # Reconstruction error\n",
    "    err_test = np.sqrt(np.sum((Otest*(X-Mgt))**2)) / np.sum(Otest) * (n*m)\n",
    "\n",
    "    # Plot\n",
    "    if not k%50:\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(1)\n",
    "        plt.imshow(X, interpolation='nearest', cmap='jet')\n",
    "        plt.title('Collaborative Filtering\\nIteration='+ str(k)+'\\nReconstruction Error= '+ str(round(err_test,5)))\n",
    "        plt.show()        \n",
    "        print('diffX',diffX)\n",
    "\n",
    "\n",
    "clear_output(wait=True) \n",
    "print('Reconstruction Error: '+ str(round(err_test,5)))\n",
    "\n",
    "# Final plot\n",
    "plt.figure(2)\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Ground truth low-rank matrix M')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet')\n",
    "plt.title('Observed values of M')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.imshow(X, interpolation='nearest', cmap='jet')\n",
    "plt.title('Collaborative Filtering\\nIteration='+ str(k)+'\\nReconstruction Error= '+ str(round(err_test,2)))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-world dataset SWEETRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : Explore different sparsity scenarios for real-world ratings\n",
    "\n",
    "Try out the following sparsity scenarios:\n",
    "* Scenario 1 : 1.3% known ratings\n",
    "* Scenario 2 : 13.1% known ratings\n",
    "* Scenario 3 : 52.7% known ratings\n",
    "\n",
    "Given that the reconstruction term weight is set to `lambdaDF = 1e1`, should the weight of the low-rank term `lambdaNuc` be increased or decreased as the number of available ratings decreases?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graphs of rows/users and columns/products\n",
    "mat = scipy.io.loadmat('datasets/real_sweetrs_scenario1.mat') # 1.3%\n",
    "mat = scipy.io.loadmat('datasets/real_sweetrs_scenario2.mat') # 13.1%\n",
    "# mat = scipy.io.loadmat('datasets/real_sweetrs_scenario3.mat') # 52.7%\n",
    "M = mat['M']\n",
    "Otraining = mat['Otraining']\n",
    "Otest = mat['Otest']\n",
    "Wrow = mat['Wrow']\n",
    "Wcol = mat['Wcol']\n",
    "print('M', M.shape)\n",
    "print('Otraining', Otraining.shape)\n",
    "print('Otest', Otest.shape)\n",
    "print('Wrow', Wrow.shape)\n",
    "print('Wcol', Wcol.shape)\n",
    "\n",
    "n,m = M.shape\n",
    "print('n,m=',n,m)\n",
    "\n",
    "Mgt = M # Ground truth\n",
    "O = Otraining\n",
    "M = O* Mgt\n",
    "perc_obs_training = np.sum(Otraining) / (n*m)\n",
    "print('perc_obs_training=',perc_obs_training)\n",
    "perc_obs_test = np.sum(Otest) / (n*m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original rating matrix\n",
    "plt.figure(1,figsize=(10,10))\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Original rating matrix\\n Percentage observed ratings: ' + str(100*np.sum(Mgt>0)/(n*m))[:5])\n",
    "\n",
    "# Visualize the observed rating matrix\n",
    "plt.figure(2, figsize=(10,10))\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Observed rating matrix\\n Percentage observed ratings: ' + str(100*perc_obs_training)[:5])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering / low-rank approximation by nuclear norm\n",
    "\n",
    "# Norm of the operator\n",
    "OM = O*M\n",
    "normOM = np.linalg.norm(OM,2)\n",
    "\n",
    "#######################################\n",
    "# Select the set of hyper-parameters\n",
    "#######################################\n",
    "\n",
    "# scenario 1 : low number of ratings, 1.3%, error metric = 743.6  \n",
    "lambdaNuc = normOM/4 * XXX ; lambdaDF = 1e1\n",
    "\n",
    "# # scenario 2 : intermediate number of ratings, 13.1%, error metric = 405.9 \n",
    "lambdaNuc = normOM/4 * XXX; lambdaDF = 1e1\n",
    "\n",
    "# # scenario 3 : large number of ratings, 52.7%, error metric = 699.3\n",
    "# lambdaNuc = normOM/4 * XXX; lambdaDF = 1e1\n",
    "\n",
    "\n",
    "# Indentify zero columns and zero rows in the data matrix X\n",
    "idx_zero_cols = np.where(np.sum(Otraining,axis=0)<1e-9)[0]\n",
    "idx_zero_rows = np.where(np.sum(Otraining,axis=1)<1e-9)[0]\n",
    "nb_zero_cols = len(idx_zero_cols)\n",
    "nb_zero_rows = len(idx_zero_rows)\n",
    "   \n",
    "# Initialization\n",
    "X = M; Xb = X;\n",
    "Y = np.zeros([n,m])\n",
    "normA = 1.\n",
    "sigma = 1./normA\n",
    "tau = 1./normA\n",
    "diffX = 1e10\n",
    "min_nm = np.min([n,m])\n",
    "k = 0\n",
    "while (k<2000) & ( diffX>1e-1 or k<100 ) :\n",
    "    \n",
    "    # Update iteration\n",
    "    k += 1\n",
    "        \n",
    "    # Update dual variable y\n",
    "    Y = Y + sigma* Xb\n",
    "    U,S,V = np.linalg.svd(Y/sigma)\n",
    "    Sdiag = shrink( S , lambdaNuc/ sigma )\n",
    "    I = np.array(range(min_nm))\n",
    "    Sshrink = np.zeros([n,m])\n",
    "    Sshrink[I,I] = Sdiag\n",
    "    Y = Y - sigma* U.dot(Sshrink.dot(V))    \n",
    "    \n",
    "    # Update primal variable x\n",
    "    Xold = X\n",
    "    X = X - tau* Y\n",
    "    X = ( X + tau* lambdaDF* O* M)/ (1 + tau* lambdaDF* O)\n",
    "    # Fix issue with no observations along some rows and columns\n",
    "    r,c = np.where(X>0.0); median = np.median(X[r,c])\n",
    "    if nb_zero_cols>0: X[:,idx_zero_cols] = median\n",
    "    if nb_zero_rows>0: X[nb_zero_rows,:] = median\n",
    "\n",
    "    # Update primal variable xb\n",
    "    Xb = 2.* X - Xold\n",
    "        \n",
    "    # Difference between two iterations\n",
    "    diffX = np.linalg.norm(X-Xold)\n",
    "        \n",
    "    # Reconstruction error\n",
    "    err_test = np.sqrt(np.sum((Otest*(X-Mgt))**2)) / np.sum(Otest) * (n*m)\n",
    "    \n",
    "    # Plot\n",
    "    if not k%50:\n",
    "        clear_output(wait=True)   \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(X, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "        plt.colorbar(shrink=0.65)\n",
    "        plt.title('Collaborative Filtering\\nIteration='+ str(k)+'\\nReconstruction Error= '+ str(round(err_test,5)))\n",
    "        plt.show()\n",
    "        print('diffX',diffX)\n",
    "\n",
    "clear_output(wait=True) \n",
    "print('Reconstruction Error: '+ str(round(err_test,5)))\n",
    "  \n",
    "\n",
    "# Final plots\n",
    "plt.figure(2, figsize=(10,10))\n",
    "plt.imshow(Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Original rating matrix\\n Percentage observed ratings: ' + str(100*np.sum(Mgt>0)/(n*m))[:5])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3, figsize=(10,10))\n",
    "plt.imshow(Otraining*Mgt, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Observed rating matrix\\n Percentage observed ratings: ' + str(100*perc_obs_training)[:5])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4, figsize=(10,10))\n",
    "plt.imshow(X, interpolation='nearest', cmap='jet', aspect=0.1)\n",
    "plt.colorbar(shrink=0.65)\n",
    "plt.title('Collaborative Filtering\\nIteration='+ str(k)+'\\nReconstruction Error= '+ str(round(err_test,5)))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
